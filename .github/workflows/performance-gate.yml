name: performance-gate

on:
  workflow_dispatch:
    inputs:
      gate_profile:
        description: "Gate profile to enforce (provisional|hard)"
        required: false
        default: provisional
      headline_scenario:
        description: "Scenario used for headline + gate checks"
        required: false
        default: ransomware
      min_runs_per_mode:
        description: "Minimum measured ON/OFF runs per platform to pass gate"
        required: false
        default: "6"
      fail_on_quality_flags:
        description: "Comma-separated quality flags that fail gate"
        required: false
        default: "low_sample_count,missing_overhead_median,missing_overhead_p95"
      trend_baseline_summary:
        description: "Optional baseline summary path/dir on runner for trend comparison"
        required: false
        default: ""
      trend_baseline_pointer:
        description: "Pointer file containing baseline path/run (default: .ci/perf-baseline.json)"
        required: false
        default: ".ci/perf-baseline.json"
      trend_baseline_pointer_strict:
        description: "Fail when pointer path is configured but missing (true|false)"
        required: false
        default: "false"
      trend_baseline_run:
        description: "Optional explicit baseline run tag for compare_trend"
        required: false
        default: ""
      trend_fail_on_regression:
        description: "Fail workflow if trend regression is detected (true|false)"
        required: false
        default: "false"
      trend_fail_on_new_quality_flags:
        description: "Treat newly introduced quality flags vs baseline as regression (true|false)"
        required: false
        default: "false"
      trend_max_regression_overhead_median_pct:
        description: "Max allowed increase vs baseline for overhead median pct"
        required: false
        default: "5.0"
      trend_max_regression_overhead_p95_pct:
        description: "Max allowed increase vs baseline for overhead p95 pct"
        required: false
        default: "8.0"
      trend_max_regression_agent_cpu_avg_s:
        description: "Max allowed increase vs baseline for agent cpu avg seconds"
        required: false
        default: "0.20"
      trend_required_platforms:
        description: "Comma-separated required platforms for trend comparison"
        required: false
        default: "linux,windows"
      trend_emit_candidate_pointer:
        description: "Emit candidate baseline pointer artifact from current run (true|false)"
        required: false
        default: "true"
  schedule:
    - cron: "15 3 * * *"
  release:
    types: [published]

permissions:
  contents: read

env:
  PERF_DATE: "${{ github.run_id }}-${{ github.run_attempt }}"

jobs:
  benchmark-linux:
    name: Benchmark Linux endpoint
    runs-on: [self-hosted, linux, eguard-perf-linux]
    timeout-minutes: 180
    steps:
      - uses: actions/checkout@v4

      - name: Run Linux phase-3 benchmark
        shell: bash
        run: |
          chmod +x scripts/perf/linux_phase3.sh
          EGUARD_PERF_DATE="${PERF_DATE}" \
          EGUARD_PERF_OUT_DIR="${GITHUB_WORKSPACE}/artifacts/perf/${PERF_DATE}/linux" \
          scripts/perf/linux_phase3.sh

      - name: Upload Linux raw artifacts
        uses: actions/upload-artifact@v4
        with:
          name: perf-linux-raw
          path: artifacts/perf/${{ env.PERF_DATE }}/linux
          if-no-files-found: error

  benchmark-windows:
    name: Benchmark Windows endpoint
    runs-on: [self-hosted, windows, eguard-perf-windows]
    timeout-minutes: 180
    steps:
      - uses: actions/checkout@v4

      - name: Run Windows phase-3 benchmark
        shell: pwsh
        run: |
          $env:EGUARD_PERF_DATE = "${env:PERF_DATE}"
          $env:EGUARD_PERF_OUT_DIR = "${env:GITHUB_WORKSPACE}/artifacts/perf/${env:PERF_DATE}/windows"
          ./scripts/perf/windows_phase3.ps1

      - name: Upload Windows raw artifacts
        uses: actions/upload-artifact@v4
        with:
          name: perf-windows-raw
          path: artifacts/perf/${{ env.PERF_DATE }}/windows
          if-no-files-found: error

  summarize-and-gate:
    name: Summarize + enforce performance gate
    needs: [benchmark-linux, benchmark-windows]
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4

      - name: Download Linux artifacts
        uses: actions/download-artifact@v4
        with:
          name: perf-linux-raw
          path: artifacts/perf/${{ env.PERF_DATE }}/linux

      - name: Download Windows artifacts
        uses: actions/download-artifact@v4
        with:
          name: perf-windows-raw
          path: artifacts/perf/${{ env.PERF_DATE }}/windows

      - name: Build summary + report
        shell: bash
        run: |
          python3 scripts/perf/summarize.py \
            --input-root "artifacts/perf/${PERF_DATE}" \
            --headline-scenario "${{ github.event.inputs.headline_scenario || 'ransomware' }}"

      - name: Enforce gate
        shell: bash
        run: |
          python3 scripts/perf/gate.py \
            --summary "artifacts/perf/${PERF_DATE}/summary.json" \
            --profile "${{ github.event.inputs.gate_profile || 'provisional' }}" \
            --min-runs-per-mode "${{ github.event.inputs.min_runs_per_mode || '6' }}" \
            --fail-on-quality-flags "${{ github.event.inputs.fail_on_quality_flags || 'low_sample_count,missing_overhead_median,missing_overhead_p95' }}" \
            --json-output "artifacts/perf/${PERF_DATE}/gate.json"

      - name: Resolve optional trend baseline
        id: resolve-trend-baseline
        shell: bash
        run: |
          cmd=(
            python3 scripts/perf/resolve_baseline.py
            --baseline-summary "${{ github.event.inputs.trend_baseline_summary || '' }}"
            --baseline-pointer "${{ github.event.inputs.trend_baseline_pointer || '.ci/perf-baseline.json' }}"
            --workspace-root "${GITHUB_WORKSPACE}"
            --json-output "artifacts/perf/${PERF_DATE}/trend-baseline-resolution.json"
            --github-output "${GITHUB_OUTPUT}"
          )

          if [[ "${{ github.event.inputs.trend_baseline_pointer_strict || 'false' }}" == "true" ]]; then
            cmd+=(--strict-pointer)
          fi

          "${cmd[@]}"

      - name: Compare trend vs optional baseline
        shell: bash
        run: |
          RESOLVED="${{ steps.resolve-trend-baseline.outputs.resolved }}"
          if [[ "${RESOLVED}" != "true" ]]; then
            echo "trend baseline not resolved; skipping trend comparison"
            exit 0
          fi

          BASELINE_INPUT="${{ steps.resolve-trend-baseline.outputs.baseline_input }}"
          BASELINE_RUN="${{ github.event.inputs.trend_baseline_run || '' }}"
          if [[ -z "${BASELINE_RUN}" ]]; then
            BASELINE_RUN="${{ steps.resolve-trend-baseline.outputs.baseline_run }}"
          fi

          if [[ -z "${BASELINE_RUN}" ]]; then
            echo "unable to resolve baseline run for trend comparison"
            exit 1
          fi

          cmd=(
            python3 scripts/perf/compare_trend.py
            --input "artifacts/perf/${PERF_DATE}"
            --input "${BASELINE_INPUT}"
            --baseline-run "${BASELINE_RUN}"
            --json-output "artifacts/perf/${PERF_DATE}/trend.json"
            --report-output "artifacts/perf/${PERF_DATE}/trend.md"
            --max-regression-overhead-median-pct "${{ github.event.inputs.trend_max_regression_overhead_median_pct || '5.0' }}"
            --max-regression-overhead-p95-pct "${{ github.event.inputs.trend_max_regression_overhead_p95_pct || '8.0' }}"
            --max-regression-agent-cpu-avg-s "${{ github.event.inputs.trend_max_regression_agent_cpu_avg_s || '0.20' }}"
            --required-platforms "${{ github.event.inputs.trend_required_platforms || 'linux,windows' }}"
          )

          if [[ "${{ github.event.inputs.trend_fail_on_new_quality_flags || 'false' }}" == "true" ]]; then
            cmd+=(--fail-on-new-quality-flags)
          fi

          if [[ "${{ github.event.inputs.trend_fail_on_regression || 'false' }}" == "true" ]]; then
            cmd+=(--fail-on-regression)
          fi

          "${cmd[@]}"

      - name: Emit baseline pointer candidate artifact
        shell: bash
        run: |
          if [[ "${{ github.event.inputs.trend_emit_candidate_pointer || 'true' }}" != "true" ]]; then
            echo "candidate baseline pointer emission disabled"
            exit 0
          fi

          python3 scripts/perf/update_baseline_pointer.py \
            --baseline-summary "artifacts/perf/${PERF_DATE}/summary.json" \
            --baseline-run "${PERF_DATE}" \
            --workspace-root "${GITHUB_WORKSPACE}" \
            --pointer-path "artifacts/perf/${PERF_DATE}/perf-baseline.candidate.json" \
            --json-output "artifacts/perf/${PERF_DATE}/perf-baseline-candidate-meta.json"

      - name: Upload summary artifacts
        uses: actions/upload-artifact@v4
        with:
          name: perf-summary
          path: |
            artifacts/perf/${{ env.PERF_DATE }}/summary.json
            artifacts/perf/${{ env.PERF_DATE }}/report.md
            artifacts/perf/${{ env.PERF_DATE }}/gate.json
            artifacts/perf/${{ env.PERF_DATE }}/trend-baseline-resolution.json
            artifacts/perf/${{ env.PERF_DATE }}/trend.json
            artifacts/perf/${{ env.PERF_DATE }}/trend.md
            artifacts/perf/${{ env.PERF_DATE }}/perf-baseline.candidate.json
            artifacts/perf/${{ env.PERF_DATE }}/perf-baseline-candidate-meta.json
          if-no-files-found: warn
